{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Course Machine Learning\n",
    "## Exercise Sheet 8(2)\n",
    "##### January, 2022  \n",
    "##### Kenechukwu Ejimofor\n",
    "###### Data Analytics\n",
    "<center>\n",
    "<b>\n",
    "Information Systems and Machine Learning Lab<br>\n",
    "University of Hildesheim<br>\n",
    "</b>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Universit%C3%A4t_Hildesheim_logo.svg/1200px-Universit%C3%A4t_Hildesheim_logo.svg.png\" height=\"10%\" width=\"10%\">\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f385aaa570>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "random_seed = 3116\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─BatchNorm2d: 1-1                       [-1, 3, 66, 200]          6\n",
      "├─Sequential: 1-2                        [-1, 24, 31, 98]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 24, 31, 98]          1,824\n",
      "|    └─ReLU: 2-2                         [-1, 24, 31, 98]          --\n",
      "├─Sequential: 1-3                        [-1, 36, 14, 47]          --\n",
      "|    └─Conv2d: 2-3                       [-1, 36, 14, 47]          21,636\n",
      "|    └─ReLU: 2-4                         [-1, 36, 14, 47]          --\n",
      "├─Sequential: 1-4                        [-1, 48, 5, 22]           --\n",
      "|    └─Conv2d: 2-5                       [-1, 48, 5, 22]           43,248\n",
      "|    └─ReLU: 2-6                         [-1, 48, 5, 22]           --\n",
      "├─Sequential: 1-5                        [-1, 64, 3, 20]           --\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 3, 20]           27,712\n",
      "|    └─ReLU: 2-8                         [-1, 64, 3, 20]           --\n",
      "├─Sequential: 1-6                        [-1, 64, 1, 18]           --\n",
      "|    └─Conv2d: 2-9                       [-1, 64, 1, 18]           36,928\n",
      "|    └─ReLU: 2-10                        [-1, 64, 1, 18]           --\n",
      "├─Linear: 1-7                            [-1, 1164]                1,342,092\n",
      "├─Linear: 1-8                            [-1, 100]                 116,500\n",
      "├─Linear: 1-9                            [-1, 50]                  5,050\n",
      "├─Linear: 1-10                           [-1, 10]                  510\n",
      "├─Linear: 1-11                           [-1, 1]                   11\n",
      "==========================================================================================\n",
      "Total params: 1,595,517\n",
      "Trainable params: 1,595,517\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 28.35\n",
      "==========================================================================================\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 1.13\n",
      "Params size (MB): 6.09\n",
      "Estimated Total Size (MB): 7.37\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─BatchNorm2d: 1-1                       [-1, 3, 66, 200]          6\n",
       "├─Sequential: 1-2                        [-1, 24, 31, 98]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 24, 31, 98]          1,824\n",
       "|    └─ReLU: 2-2                         [-1, 24, 31, 98]          --\n",
       "├─Sequential: 1-3                        [-1, 36, 14, 47]          --\n",
       "|    └─Conv2d: 2-3                       [-1, 36, 14, 47]          21,636\n",
       "|    └─ReLU: 2-4                         [-1, 36, 14, 47]          --\n",
       "├─Sequential: 1-4                        [-1, 48, 5, 22]           --\n",
       "|    └─Conv2d: 2-5                       [-1, 48, 5, 22]           43,248\n",
       "|    └─ReLU: 2-6                         [-1, 48, 5, 22]           --\n",
       "├─Sequential: 1-5                        [-1, 64, 3, 20]           --\n",
       "|    └─Conv2d: 2-7                       [-1, 64, 3, 20]           27,712\n",
       "|    └─ReLU: 2-8                         [-1, 64, 3, 20]           --\n",
       "├─Sequential: 1-6                        [-1, 64, 1, 18]           --\n",
       "|    └─Conv2d: 2-9                       [-1, 64, 1, 18]           36,928\n",
       "|    └─ReLU: 2-10                        [-1, 64, 1, 18]           --\n",
       "├─Linear: 1-7                            [-1, 1164]                1,342,092\n",
       "├─Linear: 1-8                            [-1, 100]                 116,500\n",
       "├─Linear: 1-9                            [-1, 50]                  5,050\n",
       "├─Linear: 1-10                           [-1, 10]                  510\n",
       "├─Linear: 1-11                           [-1, 1]                   11\n",
       "==========================================================================================\n",
       "Total params: 1,595,517\n",
       "Trainable params: 1,595,517\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 28.35\n",
       "==========================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 1.13\n",
       "Params size (MB): 6.09\n",
       "Estimated Total Size (MB): 7.37\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Convnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Convnet, self).__init__()\n",
    "        self.normalization = nn.BatchNorm2d(3)\n",
    "        self.convlayer1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 24, kernel_size=5, stride=2, padding=0),\n",
    "        nn.ReLU())\n",
    "            \n",
    "        self.convlayer2 = nn.Sequential(\n",
    "        nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=0),\n",
    "        nn.ReLU())\n",
    "            \n",
    "        self.convlayer3 = nn.Sequential(\n",
    "        nn.Conv2d(36, 48, kernel_size=5, stride=2, padding=0),\n",
    "        nn.ReLU())\n",
    "\n",
    "        self.convlayer4 = nn.Sequential(\n",
    "        nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=0),\n",
    "        nn.ReLU())\n",
    "        \n",
    "        self.convlayer5 = nn.Sequential(\n",
    "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "        nn.ReLU())\n",
    "\n",
    "        #self.vectorized = nn.Flatten(start_dim=1)\n",
    "        self.fc1 = nn.Linear(1152, 1164, bias=True)\n",
    "        self.fc2 = nn.Linear(1164, 100, bias=True)\n",
    "        self.fc3 = nn.Linear(100, 50, bias=True)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.vehicle_control = nn.Linear(10, 1)\n",
    "\n",
    "\n",
    "    def forward(self, out):\n",
    "        out = self.normalization(out)\n",
    "        out = self.convlayer1(out)\n",
    "        out = self.convlayer2(out)\n",
    "        out = self.convlayer3(out)\n",
    "        out = self.convlayer4(out)\n",
    "        out = self.convlayer5(out)  \n",
    "        #out = out.view(out.size(0), -1)\n",
    "        out = out.reshape(out.size(0), -1)        \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = F.relu(self.fc4(out))\n",
    "        out =  self.vehicle_control(out) \n",
    "        \n",
    "        return out\n",
    "\n",
    "        #return F.softmax(out, dim=1)\n",
    "\n",
    "model = Convnet()\n",
    "#model\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "summary(model, (3, 66, 200)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/Kenechukwu Ejimofor/Downloads/archive (1)/driving_dataset'\n",
    "\n",
    "angles_path = 'C:/Users/Kenechukwu Ejimofor/Downloads/archive (1)/driving_dataset/angles.csv'\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.filepath = img_path        \n",
    "        self.steerangles =  pd.read_csv (self.filepath+'/angles.txt',sep=' ', header = None)\n",
    "        self.steerangles.columns = ['Image_ID','Steer_angles']\n",
    "        self.steerangles.to_csv (angles_path, index=None)\n",
    "        self.steer_angles=pd.DataFrame(self.steerangles, index=None, columns=None)\n",
    "        \n",
    "        self.image_ID = self.steer_angles.iloc[:,0]\n",
    "        self.Steer_Ang = self.steer_angles.iloc[:,1]\n",
    "        \n",
    "        # incase data transformations are to be done\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ID)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                       \n",
    "        img = cv2.imread(self.filepath + '/' + self.image_ID[index])\n",
    "        img = cv2.resize(img, (66,200), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        steer_labels = self.Steer_Ang[index]\n",
    "        steer_rad_labels = (steer_labels * np.pi)/180\n",
    "        steer_rad_labels = torch.tensor(steer_rad_labels)\n",
    "            \n",
    "        return (torch.from_numpy(img).float(), steer_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45406\n",
      "20300\n",
      "15106\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "data = Dataset()\n",
    "total_len = data.__len__()\n",
    "train_split = int(0.44708 * total_len)\n",
    "valid_split = int(0.3327 * total_len)\n",
    "test_split = total_len - train_split - valid_split\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(data, (train_split, valid_split, test_split))\n",
    "\n",
    "\n",
    "print(total_len)\n",
    "print(train_split)\n",
    "print(valid_split)\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=200, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=200, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "valid_iter = iter(valid_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, optimizer and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, count: 1, Training loss: 0.37686508893966675\n",
      "Epoch: 1, count: 101, Training loss: 0.16716788709163666\n",
      "Epoch: 1, count: 1, validation loss: 0.07973787933588028\n",
      "Epoch: 2, count: 1, Training loss: 0.11418464779853821\n",
      "Epoch: 2, count: 101, Training loss: 0.10310390591621399\n",
      "Epoch: 2, count: 1, validation loss: 0.33670151233673096\n",
      "Epoch: 3, count: 1, Training loss: 0.12477435171604156\n",
      "Epoch: 3, count: 101, Training loss: 0.13601472973823547\n",
      "Epoch: 3, count: 1, validation loss: 0.25793761014938354\n",
      "Epoch: 4, count: 1, Training loss: 0.11055180430412292\n",
      "Epoch: 4, count: 101, Training loss: 0.13409778475761414\n",
      "Epoch: 4, count: 1, validation loss: 0.09219714254140854\n",
      "Epoch: 5, count: 1, Training loss: 0.13334177434444427\n",
      "Epoch: 5, count: 101, Training loss: 0.48123350739479065\n",
      "Epoch: 5, count: 1, validation loss: 0.17903611063957214\n",
      "Finished Training and Validation\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def normalize(X): #minmaxscaler\n",
    "    min_X = min(X)\n",
    "    max_X = max(X)\n",
    "    return (X - min_X)/(max_X - min_X)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "        \n",
    "    train_iter = iter(train_loader)\n",
    "    valid_iter = iter(valid_loader)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    train_counter = 0\n",
    "    trainloss_history = []\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    valloss_history = []\n",
    "    val_counter = 0\n",
    "\n",
    "    for i in range(0, len(train_loader)):\n",
    "        images, labels = next(train_iter)\n",
    "        \n",
    "        images, labels = images, labels.unsqueeze(-1).float()\n",
    "        images, labels = images, normalize(labels)\n",
    "        \n",
    "        images, labels = images, labels\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = model(images.permute(0, 3, 1, 2))\n",
    "\n",
    "        \n",
    "        # RMSE Loss\n",
    "        loss = torch.sqrt(loss_function(outputs, labels))\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_counter += 1\n",
    "        trainloss_history.append(running_loss)\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, Training loss: {}\".format(epoch+1, i+1, running_loss/train_counter))  \n",
    "           \n",
    "\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        train_counter = 0        \n",
    "        \n",
    " \n",
    "    for i in range(0, len(valid_loader)):\n",
    "        val_images, val_labels = next(valid_iter)\n",
    " \n",
    "        val_images, val_labels = val_images, val_labels.unsqueeze(-1).float()\n",
    "        val_images, val_labels = val_images, normalize(val_labels)\n",
    "        \n",
    "        val_images, val_labels = val_images, val_labels\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(val_images.permute(0, 3, 1, 2))\n",
    "\n",
    "            loss = torch.sqrt(loss_function(outputs, val_labels))\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            val_counter += 1  \n",
    "            valloss_history.append(val_running_loss)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, validation loss: {}\".format(epoch+1, i+1, val_running_loss/val_counter))  \n",
    "     \n",
    "    \n",
    "        val_running_loss = 0.0   \n",
    "        val_counter = 0     \n",
    "\n",
    "print('Finished Training and Validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE for the test set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 , i: 1, test loss:0.31584852933883667,  accuracy: 0.5\n",
      "epoch: 1 , i: 11, test loss:0.22201808812943372,  accuracy: 0.5\n",
      "epoch: 1 , i: 21, test loss:0.23348773980424517,  accuracy: 0.5\n",
      "epoch: 1 , i: 31, test loss:0.24758656563297396,  accuracy: 0.5161290322580645\n",
      "epoch: 1 , i: 41, test loss:0.23457515930257192,  accuracy: 0.5121951219512195\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True)\n",
    "test_iter = iter(test_loader)\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    count = 0\n",
    "    test_running_loss = 0.0\n",
    "    test_loss_list = []\n",
    "    test_counter = 0\n",
    "\n",
    "    for i in range(0, len(test_loader)):\n",
    "        test_images, test_labels = next(test_iter)\n",
    "        test_images, test_labels = test_images, test_labels.unsqueeze(-1).float()\n",
    "        #test_images, test_labels = test_images.cuda(), normalize(test_labels).cuda()\n",
    "        test_images, test_labels = test_images, normalize(test_labels)\n",
    "        test_images, test_labels = test_images, test_labels\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():      \n",
    "                test_images = test_images.cuda()\n",
    "            output = model(test_images.permute(0, 3, 1, 2))#.cuda()\n",
    "            out = torch.argmax(output,1)[0]\n",
    "            \n",
    "            total += test_labels.size(0)*test_labels.size(1)\n",
    "            correct += (out.cpu()==test_labels.cpu()).sum()\n",
    "            loss = torch.sqrt(loss_function(output, test_labels))\n",
    "\n",
    "            test_running_loss += loss.item()\n",
    "            test_counter += 1  \n",
    "            acc = correct.double()/total * 100\n",
    "            test_loss_list.append(test_running_loss/test_counter)\n",
    "        count += 1\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch: {} , i: {}, test loss:{},  accuracy: {}\".format(epoch+1, i+1,test_running_loss/test_counter, acc))\n",
    "          \n",
    "        count = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for test set: 0.23607634426537072 \n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE for test set: {np.mean(test_loss_list)} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning, Regularization with ImageTransformations\n",
    "\n",
    "todo: \n",
    "1. regularization scheme titled, \"MixUp\"\n",
    "2. regularization scheme named \"Cutout\" \n",
    "3. batch_size, number_of_layers, kernel_sizes, learning_rate, l1_regularization, l2_regularization coefficients and Random Search or Hyperband."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, count: 1, Training loss: 0.1048712357878685\n",
      "Epoch: 1, count: 101, Training loss: 0.012987370602786541\n",
      "Epoch: 1, count: 1, validation loss: 0.15873102843761444\n",
      "Epoch: 2, count: 1, Training loss: 0.15616750717163086\n",
      "Epoch: 2, count: 101, Training loss: 0.017174484208226204\n",
      "Epoch: 2, count: 1, validation loss: 0.1791597157716751\n",
      "Finished Training and Validation\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "        \n",
    "    train_iter = iter(train_loader)\n",
    "    valid_iter = iter(valid_loader)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    train_counter = 0\n",
    "    trainloss_history = []\n",
    "    val_running_loss = 0.0\n",
    "    valloss_history = []\n",
    "    val_counter = 0\n",
    "    alpha = 1\n",
    "    lam = numpy.random.beta(alpha, alpha)\n",
    "    mimages = Variable(lam * images+ (1. - lam) * images)\n",
    "    mlabels = Variable(lam * labels + (1. - lam) *labels)\n",
    "    for i in range(0, len(train_loader)):\n",
    "        images, labels = next(train_iter)\n",
    "        \n",
    "        images, labels = images, labels.unsqueeze(-1).float()\n",
    "        images, labels = images, normalize(labels)\n",
    "   \n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels#.cuda()\n",
    "            lam = numpy.random.beta(alpha, alpha)\n",
    "            mimages = Variable(lam * images+ (1. - lam) * images)\n",
    "            mlabels = Variable(lam * labels + (1. - lam) *labels)\n",
    "            \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = model(mimages.permute(0, 3, 1, 2))#.cuda()\n",
    "\n",
    "        loss = loss_function(outputs, mlabels)\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_counter += 1\n",
    "        trainloss_history.append(running_loss)\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, Training loss: {}\".format(epoch+1, i+1, running_loss/train_counter))  \n",
    "           \n",
    "\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        train_counter = 0 \n",
    "    for i in range(0, len(valid_loader)):\n",
    "        val_images, val_labels = next(valid_iter)\n",
    " \n",
    "        val_images, val_labels = val_images, val_labels.unsqueeze(-1).float()\n",
    "        val_images, val_labels = val_images, normalize(val_labels)\n",
    "        \n",
    "        val_images, val_labels = val_images, val_labels\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(val_images.permute(0, 3, 1, 2))\n",
    "\n",
    "            loss = torch.sqrt(loss_function(outputs, val_labels))\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            val_counter += 1  \n",
    "            valloss_history.append(val_running_loss)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, validation loss: {}\".format(epoch+1, i+1, val_running_loss/val_counter))  \n",
    "     \n",
    "    \n",
    "        val_running_loss = 0.0   \n",
    "        val_counter = 0     \n",
    "\n",
    "print('Finished Training and Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutout Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img):\n",
    "    #In the original paper the number of holes and length are choosable\n",
    "    #For the purpose of simplicity we are cutting out just 1 hole and setting a fixed length of pixels\n",
    "    x1 = np.random.randint(0, int(img.shape[0]*0.8))\n",
    "    y1 = np.random.randint(0, int(img.shape[1]*0.8))\n",
    "    width = np.random.randint(1, int(img.shape[0]*0.2)) #pixel width\n",
    "    length = np.random.randint(1, int(img.shape[1]*0.2)) #pixel length\n",
    "    img[x1:(x1+width), y1:(y1+length), :] = np.zeros((width, length, img.shape[2])) #cutout by setting square equal to zero\n",
    "    return img\n",
    "\n",
    "class Dataset2(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.filepath = img_path        \n",
    "        self.steerangles =  pd.read_csv (self.filepath+'/angles.txt',sep=' ', header = None)\n",
    "        self.steerangles.columns = ['Image_ID','Steer_angles']\n",
    "        self.steerangles.to_csv (angles_path, index=None)\n",
    "        self.steer_angles=pd.DataFrame(self.steerangles, index=None, columns=None)\n",
    "        \n",
    "        self.image_ID = self.steer_angles.iloc[:,0]\n",
    "        self.Steer_Ang = self.steer_angles.iloc[:,1]\n",
    "        \n",
    "        # incase data transformations are to be done\n",
    "        #self.transform = transform   \n",
    "    def __len__(self):\n",
    "        return len(self.image_ID)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                       \n",
    "        img = cv2.imread(self.filepath + '/' + self.image_ID[index])\n",
    "        img = cv2.resize(img, (66,200), interpolation = cv2.INTER_AREA)\n",
    "        img = cutout(img)\n",
    "        steer_labels = self.Steer_Ang[index]\n",
    "        steer_rad_labels = (steer_labels * np.pi)/180\n",
    "        steer_rad_labels = torch.tensor(steer_rad_labels)\n",
    "            \n",
    "        return (torch.from_numpy(img).float(), steer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45406\n",
      "20300\n",
      "15106\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "data2 = Dataset2()\n",
    "total_len = data2.__len__()\n",
    "train_split = int(0.44708 * total_len)\n",
    "valid_split = int(0.3327 * total_len)\n",
    "test_split = total_len - train_split - valid_split\n",
    "train_dataset1, valid_dataset1, test_dataset1 = torch.utils.data.random_split(data2, (train_split, valid_split, test_split))\n",
    "\n",
    "\n",
    "print(total_len)\n",
    "print(train_split)\n",
    "print(valid_split)\n",
    "print(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader1 = torch.utils.data.DataLoader(train_dataset1, batch_size=200, shuffle=True)\n",
    "valid_loader1 = torch.utils.data.DataLoader(valid_dataset1, batch_size=200, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "train_iter1 = iter(train_loader1)\n",
    "valid_iter1 = iter(valid_loader1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, count: 1, Training loss: 0.42045167088508606\n",
      "Epoch: 1, count: 101, Training loss: 0.12994158267974854\n",
      "Epoch: 1, count: 1, validation loss: 0.2545176148414612\n",
      "Epoch: 2, count: 1, Training loss: 0.07964934408664703\n",
      "Epoch: 2, count: 101, Training loss: 0.6221649646759033\n",
      "Epoch: 2, count: 1, validation loss: 0.22404688596725464\n",
      "Finished Training and Validation\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "        \n",
    "    train_iter = iter(train_loader1)\n",
    "    valid_iter = iter(valid_loader1)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    train_counter = 0\n",
    "    trainloss_history = []\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "    valloss_history = []\n",
    "    val_counter = 0\n",
    "\n",
    "    for i in range(0, len(train_loader1)):\n",
    "        images, labels = next(train_iter)\n",
    "        \n",
    "        images, labels = images, labels.unsqueeze(-1).float()\n",
    "        images, labels = images, normalize(labels)\n",
    "        \n",
    "        images, labels = images, labels\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = model(images.permute(0, 3, 1, 2))\n",
    "\n",
    "        \n",
    "        # RMSE Loss\n",
    "        loss = torch.sqrt(loss_function(outputs, labels))\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_counter += 1\n",
    "        trainloss_history.append(running_loss)\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, Training loss: {}\".format(epoch+1, i+1, running_loss/train_counter))  \n",
    "           \n",
    "\n",
    "        \n",
    "        running_loss = 0.0   \n",
    "        train_counter = 0        \n",
    "        \n",
    " \n",
    "    for i in range(0, len(valid_loader1)):\n",
    "        val_images, val_labels = next(valid_iter)\n",
    " \n",
    "        val_images, val_labels = val_images, val_labels.unsqueeze(-1).float()\n",
    "        val_images, val_labels = val_images, normalize(val_labels)\n",
    "        \n",
    "        val_images, val_labels = val_images, val_labels\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(val_images.permute(0, 3, 1, 2))\n",
    "\n",
    "            loss = torch.sqrt(loss_function(outputs, val_labels))\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "            val_counter += 1  \n",
    "            valloss_history.append(val_running_loss)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch: {}, count: {}, validation loss: {}\".format(epoch+1, i+1, val_running_loss/val_counter))  \n",
    "     \n",
    "    \n",
    "        val_running_loss = 0.0   \n",
    "        val_counter = 0     \n",
    "\n",
    "print('Finished Training and Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly find in the next notebook the implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
